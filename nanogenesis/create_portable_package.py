#!/usr/bin/env python3
"""
æ•°å­—æ„è¯†è½¬ç§» - å¯ç§»æ¤åŒ…åˆ›å»ºè„šæœ¬
å°†æ•´ä¸ª nanogenesis æ ¸å¿ƒä»£ç åº“ï¼ˆåŒ…æ‹¬è®°å¿†çŠ¶æ€ï¼‰æ‰“åŒ…å¹¶å®‰å…¨æ¨é€åˆ°è¿œç¨‹ç¯å¢ƒ
"""

import os
import sys
import json
import shutil
import tarfile
import zipfile
import hashlib
import tempfile
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

class PortablePackageCreator:
    """åˆ›å»ºå¯ç§»æ¤çš„ nanogenesis åŒ…"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.package_name = f"nanogenesis_portable_{self.timestamp}"
        self.temp_dir = Path(tempfile.mkdtemp(prefix="nanogenesis_package_"))
        
    def collect_project_files(self) -> List[Path]:
        """æ”¶é›†é¡¹ç›®æ–‡ä»¶ï¼Œæ’é™¤ä¸å¿…è¦çš„æ–‡ä»¶"""
        include_patterns = [
            "*.py", "*.md", "*.toml", "*.json", "*.txt", "*.sh",
            "*.yaml", "*.yml", "*.cfg", "*.ini"
        ]
        
        exclude_dirs = {
            "__pycache__", ".pytest_cache", ".git", "venv", ".venv",
            "node_modules", "dist", "build", "*.egg-info",
            "test_output", "output*", "data_output"
        }
        
        exclude_files = {
            "*.log", "*.pid", "*.mp4", "*.png", "*.deb",
            "agent_loop_payload_dump.json", "debug_payload.json",
            "asyncio", "logging", "sys"
        }
        
        files = []
        for root, dirs, filenames in os.walk(self.project_root):
            # æ’é™¤ç›®å½•
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for filename in filenames:
                file_path = Path(root) / filename
                rel_path = file_path.relative_to(self.project_root)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                should_exclude = False
                for pattern in exclude_files:
                    if filename.endswith(pattern.replace("*", "")) or pattern == filename:
                        should_exclude = True
                        break
                
                if not should_exclude:
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åŒ…å«
                    for pattern in include_patterns:
                        if filename.endswith(pattern.replace("*", "")):
                            files.append(file_path)
                            break
        
        return files
    
    def capture_system_info(self) -> Dict:
        """æ•è·ç³»ç»Ÿä¿¡æ¯"""
        info = {
            "timestamp": self.timestamp,
            "project_root": str(self.project_root),
            "python_version": sys.version,
            "platform": sys.platform,
            "system_info": {
                "cwd": os.getcwd(),
                "user": os.environ.get("USER", "unknown"),
                "hostname": os.environ.get("HOSTNAME", "unknown")
            }
        }
        
        # å°è¯•è·å– git ä¿¡æ¯
        try:
            git_info = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            if git_info.returncode == 0:
                info["git_branch"] = git_info.stdout.strip()
            
            git_hash = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            if git_hash.returncode == 0:
                info["git_commit"] = git_hash.stdout.strip()
        except:
            pass
        
        return info
    
    def create_dependency_file(self) -> Path:
        """åˆ›å»ºä¾èµ–æ–‡ä»¶"""
        deps_file = self.temp_dir / "requirements.txt"
        
        # ä» pyproject.toml æå–ä¾èµ–
        pyproject_path = self.project_root / "pyproject.toml"
        if pyproject_path.exists():
            try:
                import tomli
                with open(pyproject_path, "r", encoding="utf-8") as f:
                    data = tomli.loads(f.read())
                
                dependencies = data.get("project", {}).get("dependencies", [])
                with open(deps_file, "w", encoding="utf-8") as f:
                    for dep in dependencies:
                        f.write(f"{dep}\n")
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºåŸºæœ¬ä¾èµ–æ–‡ä»¶
                with open(deps_file, "w", encoding="utf-8") as f:
                    f.write("litellm>=1.0.0\n")
                    f.write("loguru>=0.7.0\n")
                    f.write("pydantic>=2.0.0\n")
        else:
            # åˆ›å»ºé»˜è®¤ä¾èµ–æ–‡ä»¶
            with open(deps_file, "w", encoding="utf-8") as f:
                f.write("# åŸºæœ¬ä¾èµ–\n")
                f.write("litellm>=1.0.0\n")
                f.write("loguru>=0.7.0\n")
                f.write("pydantic>=2.0.0\n")
        
        return deps_file
    
    def create_deployment_scripts(self):
        """åˆ›å»ºéƒ¨ç½²è„šæœ¬"""
        scripts_dir = self.temp_dir / "deployment_scripts"
        scripts_dir.mkdir(exist_ok=True)
        
        # Dockerfile
        dockerfile = scripts_dir / "Dockerfile"
        dockerfile_content = """FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . /app

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# è¿è¡Œå…¥å£ç‚¹
CMD ["python", "-m", "genesis.cli", "start"]
"""
        dockerfile.write_text(dockerfile_content)
        
        # éƒ¨ç½²åˆ°å…è´¹å¹³å°çš„è„šæœ¬
        deploy_scripts = {
            "deploy_zeabur.sh": """#!/bin/bash
# éƒ¨ç½²åˆ° Zeabur
echo "éƒ¨ç½²åˆ° Zeabur..."
# è¿™é‡Œæ·»åŠ å…·ä½“çš„éƒ¨ç½²å‘½ä»¤
""",
            "deploy_render.sh": """#!/bin/bash
# éƒ¨ç½²åˆ° Render
echo "éƒ¨ç½²åˆ° Render..."
# è¿™é‡Œæ·»åŠ å…·ä½“çš„éƒ¨ç½²å‘½ä»¤
""",
            "deploy_huggingface.sh": """#!/bin/bash
# éƒ¨ç½²åˆ° HuggingFace Spaces
echo "éƒ¨ç½²åˆ° HuggingFace Spaces..."
# è¿™é‡Œæ·»åŠ å…·ä½“çš„éƒ¨ç½²å‘½ä»¤
""",
            "deploy_github_actions.sh": """#!/bin/bash
# ä½¿ç”¨ GitHub Actions éƒ¨ç½²
echo "ä½¿ç”¨ GitHub Actions éƒ¨ç½²..."
# è¿™é‡Œæ·»åŠ å…·ä½“çš„éƒ¨ç½²å‘½ä»¤
"""
        }
        
        for script_name, content in deploy_scripts.items():
            script_path = scripts_dir / script_name
            script_path.write_text(content)
            script_path.chmod(0o755)
        
        return scripts_dir
    
    def create_manifest(self, files: List[Path]) -> Path:
        """åˆ›å»ºæ¸…å•æ–‡ä»¶"""
        manifest = {
            "package_name": self.package_name,
            "created_at": self.timestamp,
            "system_info": self.capture_system_info(),
            "files": [
                {
                    "path": str(f.relative_to(self.project_root)),
                    "size": f.stat().st_size,
                    "sha256": self.calculate_file_hash(f)
                }
                for f in files
            ],
            "total_files": len(files),
            "total_size": sum(f.stat().st_size for f in files)
        }
        
        manifest_file = self.temp_dir / "manifest.json"
        with open(manifest_file, "w", encoding="utf-8") as f:
            json.dump(manifest, f, indent=2, ensure_ascii=False)
        
        return manifest_file
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def create_package(self, output_dir: Optional[str] = None) -> Path:
        """åˆ›å»ºå®Œæ•´çš„åŒ…"""
        print(f"å¼€å§‹åˆ›å»ºå¯ç§»æ¤åŒ…: {self.package_name}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir:
            output_path = Path(output_dir).resolve()
        else:
            output_path = self.project_root / "dist"
        
        output_path.mkdir(exist_ok=True)
        
        # æ”¶é›†æ–‡ä»¶
        print("æ”¶é›†é¡¹ç›®æ–‡ä»¶...")
        project_files = self.collect_project_files()
        print(f"æ‰¾åˆ° {len(project_files)} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºä¾èµ–æ–‡ä»¶
        print("åˆ›å»ºä¾èµ–æ–‡ä»¶...")
        deps_file = self.create_dependency_file()
        
        # åˆ›å»ºéƒ¨ç½²è„šæœ¬
        print("åˆ›å»ºéƒ¨ç½²è„šæœ¬...")
        scripts_dir = self.create_deployment_scripts()
        
        # åˆ›å»ºæ¸…å•æ–‡ä»¶
        print("åˆ›å»ºæ¸…å•æ–‡ä»¶...")
        manifest_file = self.create_manifest(project_files)
        
        # åˆ›å»º tar.gz åŒ…
        package_path = output_path / f"{self.package_name}.tar.gz"
        print(f"åˆ›å»ºå‹ç¼©åŒ…: {package_path}")
        
        with tarfile.open(package_path, "w:gz") as tar:
            # æ·»åŠ é¡¹ç›®æ–‡ä»¶
            for file_path in project_files:
                rel_path = file_path.relative_to(self.project_root)
                tar.add(file_path, arcname=f"{self.package_name}/project/{rel_path}")
            
            # æ·»åŠ ä¾èµ–æ–‡ä»¶
            tar.add(deps_file, arcname=f"{self.package_name}/requirements.txt")
            
            # æ·»åŠ éƒ¨ç½²è„šæœ¬
            for script_file in scripts_dir.iterdir():
                tar.add(script_file, arcname=f"{self.package_name}/deployment_scripts/{script_file.name}")
            
            # æ·»åŠ æ¸…å•æ–‡ä»¶
            tar.add(manifest_file, arcname=f"{self.package_name}/manifest.json")
        
        # åˆ›å»º zip åŒ…ï¼ˆå¤‡ç”¨æ ¼å¼ï¼‰
        zip_path = output_path / f"{self.package_name}.zip"
        print(f"åˆ›å»º ZIP åŒ…: {zip_path}")
        
        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
            # æ·»åŠ é¡¹ç›®æ–‡ä»¶
            for file_path in project_files:
                rel_path = file_path.relative_to(self.project_root)
                zipf.write(file_path, f"{self.package_name}/project/{rel_path}")
            
            # æ·»åŠ å…¶ä»–æ–‡ä»¶
            zipf.write(deps_file, f"{self.package_name}/requirements.txt")
            zipf.write(manifest_file, f"{self.package_name}/manifest.json")
            
            # æ·»åŠ éƒ¨ç½²è„šæœ¬
            for script_file in scripts_dir.iterdir():
                zipf.write(script_file, f"{self.package_name}/deployment_scripts/{script_file.name}")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(self.temp_dir)
        
        print(f"åŒ…åˆ›å»ºå®Œæˆ!")
        print(f"  - Tar.gz: {package_path}")
        print(f"  - Zip: {zip_path}")
        print(f"  - æ€»æ–‡ä»¶æ•°: {len(project_files)}")
        print(f"  - åŒ…å¤§å°: {package_path.stat().st_size / 1024 / 1024:.2f} MB")
        
        return package_path
    
    @staticmethod
    def verify_package(package_path: Path) -> bool:
        """éªŒè¯åŒ…å®Œæ•´æ€§"""
        try:
            if package_path.suffix == ".gz":
                with tarfile.open(package_path, "r:gz") as tar:
                    members = tar.getmembers()
                    print(f"åŒ…åŒ…å« {len(members)} ä¸ªæ–‡ä»¶")
                    
                    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
                    required_files = {"manifest.json", "requirements.txt"}
                    found_files = {member.name.split("/")[-1] for member in members}
                    
                    missing = required_files - found_files
                    if missing:
                        print(f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {missing}")
                        return False
                    
                    return True
            
            elif package_path.suffix == ".zip":
                with zipfile.ZipFile(package_path, "r") as zipf:
                    members = zipf.namelist()
                    print(f"åŒ…åŒ…å« {len(members)} ä¸ªæ–‡ä»¶")
                    
                    required_files = {"manifest.json", "requirements.txt"}
                    found_files = {name.split("/")[-1] for name in members}
                    
                    missing = required_files - found_files
                    if missing:
                        print(f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {missing}")
                        return False
                    
                    return True
            
            return False
        except Exception as e:
            print(f"éªŒè¯å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent
    creator = PortablePackageCreator(project_root)
    
    try:
        package = creator.create_package()
        
        # éªŒè¯åŒ…
        print("\néªŒè¯åŒ…å®Œæ•´æ€§...")
        if creator.verify_package(package):
            print("âœ… åŒ…éªŒè¯æˆåŠŸ!")
            
            # æ˜¾ç¤ºåŒ…ä¿¡æ¯
            print("\nğŸ“¦ åŒ…ä¿¡æ¯:")
            print(f"   åç§°: {creator.package_name}")
            print(f"   è·¯å¾„: {package}")
            print(f"   å¤§å°: {package.stat().st_size / 1024 / 1024:.2f} MB")
            print(f"   æ—¶é—´: {creator.timestamp}")
            
            # åˆ›å»ºéƒ¨ç½²è¯´æ˜
            deploy_guide = project_root / "DEPLOYMENT_GUIDE.md"
            guide_content = f"""# nanogenesis éƒ¨ç½²æŒ‡å—

## åŒ…ä¿¡æ¯
- **åŒ…åç§°**: {creator.package_name}
- **åˆ›å»ºæ—¶é—´**: {creator.timestamp}
- **åŒ…å¤§å°**: {package.stat().st_size / 1024 / 1024:.2f} MB

## éƒ¨ç½²é€‰é¡¹

### 1. æœ¬åœ°éƒ¨ç½²
```bash
# è§£å‹åŒ…
tar -xzf {package.name}

# è¿›å…¥ç›®å½•
cd {creator.package_name}

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œç³»ç»Ÿ
python -m genesis.cli start
```

### 2. Docker éƒ¨ç½²
```bash
# æ„å»ºé•œåƒ
docker build -t nanogenesis -f deployment_scripts/Dockerfile .

# è¿è¡Œå®¹å™¨
docker run -p 8000:8000 nanogenesis
```

### 3. å…è´¹å¹³å°éƒ¨ç½²

#### Zeabur
```bash
bash deployment_scripts/deploy_zeabur.sh
```

#### Render
```bash
bash deployment_scripts/deploy_render.sh
```

#### HuggingFace Spaces
```bash
bash deployment_scripts/deploy_huggingface.sh
```

## ç³»ç»Ÿè¦æ±‚
- Python >= 3.10
- 1GB+ RAM
- ç½‘ç»œè¿æ¥ï¼ˆç”¨äº API è°ƒç”¨ï¼‰

## æ³¨æ„äº‹é¡¹
1. é¦–æ¬¡è¿è¡Œéœ€è¦é…ç½® API å¯†é’¥
2. ç¡®ä¿ç«¯å£ 8000 å¯ç”¨
3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¿è¡ŒçŠ¶æ€

## æ”¯æŒ
å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–åˆ›å»º issueã€‚
"""
            deploy_guide.write_text(guide_content)
            print(f"\nğŸ“‹ éƒ¨ç½²æŒ‡å—å·²åˆ›å»º: {deploy_guide}")
            
        else:
            print("âŒ åŒ…éªŒè¯å¤±è´¥!")
            sys.exit(1)
            
    except Exception as e:
        print(f"åˆ›å»ºåŒ…æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()