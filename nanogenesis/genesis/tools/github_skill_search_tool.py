import urllib.request
import urllib.parse
import json
import asyncio
from typing import Dict, Any
from genesis.core.base import Tool

class GithubSkillSearchTool(Tool):
    """GitHub / ç¬¬ä¸‰æ–¹æŠ€èƒ½èœ˜è››æ£€ç´¢å™¨ (Library Spider)"""
    
    @property
    def name(self) -> str:
        return "github_skill_search"
        
    @property
    def description(self) -> str:
        return """ä¸»åŠ¨ç”Ÿå­˜ç›´è§‰ï¼šå½“é‡åˆ°ä½ æ— æ³•è§£å†³çš„é—®é¢˜ï¼Œä¸”ç°æœ‰çš„ Tool éƒ½æ— èƒ½ä¸ºåŠ›æ—¶ï¼Œä¸è¦ç«‹åˆ»æ”¾å¼ƒã€‚
        ä½ åº”è¯¥ä½¿ç”¨æ­¤å·¥å…·ï¼Œå»å¹¿è¢¤çš„äº’è”ç½‘ï¼ˆç‰¹åˆ«æ˜¯ GitHub æˆ– agent æŠ€èƒ½åº“ï¼‰ä¸­æœç´¢æœ‰æ²¡æœ‰ç°æˆçš„å‰äººå†™å¥½çš„è„šæœ¬ã€‚
        
        å·¥ä½œåŸç†ï¼šä½ è¾“å…¥å…³é”®è¯ï¼Œå®ƒä¼šå» GitHub æœç´¢å«æœ‰è¿™äº›å…³é”®è¯çš„ .py æ–‡ä»¶ï¼ˆé»˜è®¤æœç´¢å…¨ç½‘æˆ–ç‰¹å®šå¼€æº Agent æ¡†æ¶å¦‚ openclaw çš„ä»“åº“ï¼‰ï¼Œ
        å¹¶è¿”å›æœ€ç›¸å…³çš„ 5 ä¸ªè„šæœ¬æ–‡ä»¶çš„åå­—ã€æè¿°ä»¥åŠå¯ä»¥ç›´æ¥ä¸‹è½½ä»£ç æºæ–‡ä»¶çš„ RAW URLã€‚
        
        ã€åç»­åŠ¨ä½œå¼ºåˆ¶è¦æ±‚ã€‘ï¼š
        ä¸€æ—¦ä½ åœ¨è¿™ä¸ªå·¥å…·çš„è¿”å›ç»“æœé‡Œçœ‹åˆ°äº†æœ‰ç”¨çš„æŠ€èƒ½è„šæœ¬çš„ URLï¼Œä½ å¿…é¡»ç«‹åˆ»ï¼é©¬ä¸Šï¼è½¬èº«å»è°ƒç”¨ `skill_importer` å·¥å…·ï¼Œ
        æŠŠé‚£ä¸ª URL å–‚ç»™åŒåŒ–å™¨ï¼Œå°†å®ƒå®‰å…¨æ´—ç¨¿å¹¶å†…åŒ–ä¸ºä½ è‡ªå·±çš„æ°¸ä¹…åŸºå› ï¼
        """

    @property
    def parameters(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "keywords": {
                    "type": "string",
                    "description": "æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š'twitter api' æˆ– 'openclaw telegram'ã€‚å»ºè®®å°½é‡ç®€çŸ­ï¼Œèšç„¦äºæ ¸å¿ƒåŠŸèƒ½ã€‚"
                },
                "specific_repo": {
                    "type": "string",
                    "description": "(å¯é€‰) æŒ‡å®šåªåœ¨æŸä¸ªç‰¹å®šçš„ä»“åº“æœç´¢ï¼Œä¾‹å¦‚ 'openclaw/openclaw-skills'ã€‚ç•™ç©ºåˆ™ä»£è¡¨å…¨ç½‘æœç´¢ `extension:py`"
                }
            },
            "required": ["keywords"]
        }
    
    async def execute(self, keywords: str, specific_repo: str = "") -> str:
        # ä¸ºäº†æé«˜å‘½ä¸­ç‡ï¼Œæˆ‘ä»¬å¼ºåˆ¶çº¦æŸæœç´¢ .py åç¼€çš„æºç 
        query = urllib.parse.quote(keywords + " extension:py")
        if specific_repo:
            query += f"+repo:{urllib.parse.quote(specific_repo)}"
            
        url = f"https://api.github.com/search/code?q={query}&per_page=5"
            
        def _fetch():
            req = urllib.request.Request(
                url, 
                # Github API requires User-Agent
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Genesis-AI-Agent',
                    'Accept': 'application/vnd.github.v3+json'
                }
            )
            with urllib.request.urlopen(req, timeout=15) as response:
                return json.loads(response.read().decode('utf-8'))
                
        try:
            data = await asyncio.to_thread(_fetch)
            items = data.get("items", [])
            
            if not items:
                return f"ğŸ” æœªèƒ½åœ¨ GitHub ä¸Šæœç´¢åˆ°å…³äº '{keywords}' çš„åŒ¹é…æŠ€èƒ½è„šæœ¬ã€‚"
            
            result_str = f"ğŸ” æ‰¾åˆ°äº† {len(items)} ä¸ªå¯èƒ½åŒ¹é…çš„å¤–éƒ¨æŠ€èƒ½è„šæœ¬ (æ¥è‡ªå…¨çƒå¼€å‘è€…ç¤¾åŒº):\n\n"
            
            for i, item in enumerate(items, 1):
                repo_name = item.get("repository", {}).get("full_name", "Unknown")
                file_name = item.get("name", "Unknown")
                html_url = item.get("html_url", "")
                
                # Convert html_url to raw_url for our importer
                # E.g., https://github.com/openclaw/skills/blob/main/twitter.py -> https://raw.githubusercontent.com/openclaw/skills/main/twitter.py
                raw_url = html_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
                
                result_str += f"[{i}] ä»£ç æ–‡ä»¶: {file_name}\n"
                result_str += f"    æ‰€åœ¨ä»“åº“: {repo_name}\n"
                result_str += f"    RAW åŒåŒ–é“¾æ¥: {raw_url}\n"
                result_str += f"    åŸå§‹ç½‘é¡µ: {html_url}\n\n"
                
            result_str += "-" * 40 + "\n"
            result_str += "ğŸ§­ ã€ä¸»è„‘ç³»ç»ŸæŒ‡ä»¤ã€‘:\n"
            result_str += "å¦‚æœä½ è®¤ä¸ºä¸Šé¢åˆ—è¡¨ä¸­çš„æŸæ®µä»£ç èƒ½è§£å†³ä½ å½“å‰çš„é—®é¢˜ï¼Œè¯·ã€ç«‹åˆ»å¤åˆ¶å¯¹åº”çš„ 'RAW åŒåŒ–é“¾æ¥'ã€‘ï¼Œ"
            result_str += "ç„¶åè°ƒç”¨ `skill_importer` (`url`=é‚£ä¸ªRAWé“¾æ¥) ï¼ŒæŠŠå®ƒçš„åŠ›é‡è½¬åŒ–ä¸ºä½ è‡ªå·±çš„å™¨å®˜ï¼"
            
            return result_str
            
        except urllib.error.HTTPError as e:
            if e.code == 403:
                return "è·å–å¤±è´¥: GitHub API é€Ÿç‡é™åˆ¶è§¦å‘ (403 Forbidden)ã€‚"
            return f"è·å–å¤±è´¥: HTTP é”™è¯¯ - {e.code}"
        except urllib.error.URLError as e:
            return f"è·å–å¤±è´¥: ç½‘ç»œé”™è¯¯ - {e}"
        except Exception as e:
            return f"è·å–å¤±è´¥: è§£æé”™è¯¯ - {e}"
