#!/usr/bin/env python3
"""
å¸‚åœºæ•°æ®é‡‡é›†å·¥å…·
ç”¨äºæ”¶é›†å’Œåˆ†æåœ¨çº¿èµšé’±æœºä¼š
"""

import requests
import json
import time
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MarketDataCollector:
    """å¸‚åœºæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, db_path: str = "market_data.db"):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºæœºä¼šè¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS opportunities (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            description TEXT,
            category TEXT,
            platform TEXT,
            estimated_earnings TEXT,
            skill_requirements TEXT,
            time_commitment TEXT,
            popularity_score INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # åˆ›å»ºè¶‹åŠ¿è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS trends (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword TEXT NOT NULL,
            search_volume INTEGER,
            competition_level TEXT,
            trend_direction TEXT,
            collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    def collect_online_opportunities(self) -> List[Dict]:
        """æ”¶é›†åœ¨çº¿èµšé’±æœºä¼š"""
        opportunities = []
        
        # æ¨¡æ‹Ÿæ”¶é›†ä¸€äº›å¸¸è§çš„æœºä¼š
        sample_opportunities = [
            {
                "title": "è‡ªç”±èŒä¸šç¼–ç¨‹é¡¹ç›®",
                "description": "ä¸ºä¸­å°ä¼ä¸šå¼€å‘ç½‘ç«™å’Œåº”ç”¨ç¨‹åº",
                "category": "ç¼–ç¨‹",
                "platform": "Upwork/Freelancer",
                "estimated_earnings": "$20-100/å°æ—¶",
                "skill_requirements": "Python, JavaScript, Webå¼€å‘",
                "time_commitment": "çµæ´»",
                "popularity_score": 85
            },
            {
                "title": "å†…å®¹åˆ›ä½œå’ŒSEOä¼˜åŒ–",
                "description": "ä¸ºåšå®¢å’Œç½‘ç«™åˆ›å»ºä¼˜åŒ–å†…å®¹",
                "category": "å†™ä½œ",
                "platform": "Fiverr/Content Agencies",
                "estimated_earnings": "$0.05-0.20/è¯",
                "skill_requirements": "è‹±è¯­å†™ä½œ, SEOçŸ¥è¯†",
                "time_commitment": "çµæ´»",
                "popularity_score": 78
            },
            {
                "title": "æ•°æ®æ ‡æ³¨å’ŒAIè®­ç»ƒ",
                "description": "ä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹æ ‡æ³¨æ•°æ®",
                "category": "AI",
                "platform": "Appen/Lionbridge",
                "estimated_earnings": "$10-25/å°æ—¶",
                "skill_requirements": "åŸºç¡€è®¡ç®—æœºæŠ€èƒ½",
                "time_commitment": "çµæ´»",
                "popularity_score": 72
            },
            {
                "title": "åœ¨çº¿è¯¾ç¨‹åˆ›å»º",
                "description": "åˆ›å»ºå’Œé”€å”®ä¸“ä¸šçŸ¥è¯†è¯¾ç¨‹",
                "category": "æ•™è‚²",
                "platform": "Udemy/Coursera",
                "estimated_earnings": "è¢«åŠ¨æ”¶å…¥ï¼Œ$100-5000/æœˆ",
                "skill_requirements": "ä¸“ä¸šçŸ¥è¯†, æ•™å­¦èƒ½åŠ›",
                "time_commitment": "å‰æœŸæŠ•å…¥å¤§",
                "popularity_score": 65
            },
            {
                "title": "ç”µå•†ä»£è¿è¥",
                "description": "å¸®åŠ©å•†å®¶ç®¡ç†åœ¨çº¿åº—é“º",
                "category": "ç”µå•†",
                "platform": "Shopify/Amazon",
                "estimated_earnings": "$500-3000/æœˆ",
                "skill_requirements": "ç”µå•†å¹³å°æ“ä½œ, è¥é”€",
                "time_commitment": "æŒç»­",
                "popularity_score": 80
            }
        ]
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for opp in sample_opportunities:
            cursor.execute('''
            INSERT INTO opportunities 
            (title, description, category, platform, estimated_earnings, skill_requirements, time_commitment, popularity_score)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                opp["title"], opp["description"], opp["category"], opp["platform"],
                opp["estimated_earnings"], opp["skill_requirements"], opp["time_commitment"],
                opp["popularity_score"]
            ))
        
        conn.commit()
        conn.close()
        
        logger.info(f"æ”¶é›†åˆ° {len(sample_opportunities)} ä¸ªèµšé’±æœºä¼š")
        return sample_opportunities
    
    def analyze_trends(self) -> List[Dict]:
        """åˆ†æå¸‚åœºè¶‹åŠ¿"""
        trends = [
            {
                "keyword": "AIè‡ªåŠ¨åŒ–",
                "search_volume": 8500,
                "competition_level": "é«˜",
                "trend_direction": "ä¸Šå‡"
            },
            {
                "keyword": "è¿œç¨‹å·¥ä½œ",
                "search_volume": 12000,
                "competition_level": "ä¸­",
                "trend_direction": "ç¨³å®š"
            },
            {
                "keyword": "è¢«åŠ¨æ”¶å…¥",
                "search_volume": 9500,
                "competition_level": "é«˜",
                "trend_direction": "ä¸Šå‡"
            },
            {
                "keyword": "è‡ªç”±èŒä¸š",
                "search_volume": 15000,
                "competition_level": "ä¸­",
                "trend_direction": "ç¨³å®š"
            },
            {
                "keyword": "åœ¨çº¿æ•™è‚²",
                "search_volume": 7800,
                "competition_level": "ä¸­",
                "trend_direction": "ä¸Šå‡"
            }
        ]
        
        # ä¿å­˜è¶‹åŠ¿æ•°æ®
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for trend in trends:
            cursor.execute('''
            INSERT INTO trends (keyword, search_volume, competition_level, trend_direction)
            VALUES (?, ?, ?, ?)
            ''', (trend["keyword"], trend["search_volume"], 
                  trend["competition_level"], trend["trend_direction"]))
        
        conn.commit()
        conn.close()
        
        logger.info(f"åˆ†æåˆ° {len(trends)} ä¸ªå¸‚åœºè¶‹åŠ¿")
        return trends
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æœºä¼šç»Ÿè®¡
        cursor.execute('SELECT COUNT(*) FROM opportunities')
        opp_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(popularity_score) FROM opportunities')
        avg_popularity = cursor.fetchone()[0]
        
        # è·å–çƒ­é—¨ç±»åˆ«
        cursor.execute('''
        SELECT category, COUNT(*) as count, AVG(popularity_score) as avg_score
        FROM opportunities 
        GROUP BY category 
        ORDER BY avg_score DESC
        ''')
        categories = cursor.fetchall()
        
        # è·å–è¶‹åŠ¿æ•°æ®
        cursor.execute('''
        SELECT keyword, search_volume, trend_direction
        FROM trends 
        ORDER BY search_volume DESC
        LIMIT 5
        ''')
        top_trends = cursor.fetchall()
        
        conn.close()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# å¸‚åœºæ•°æ®åˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¦‚è§ˆ
- å‘ç°æœºä¼šæ€»æ•°: {opp_count}
- å¹³å‡å—æ¬¢è¿åº¦: {avg_popularity:.1f}/100

## çƒ­é—¨ç±»åˆ«æ’å
"""
        
        for category, count, avg_score in categories:
            report += f"- {category}: {count}ä¸ªæœºä¼šï¼Œå¹³å‡åˆ†{avg_score:.1f}\n"
        
        report += "\n## çƒ­é—¨è¶‹åŠ¿å…³é”®è¯\n"
        for keyword, volume, direction in top_trends:
            trend_icon = "ğŸ“ˆ" if direction == "ä¸Šå‡" else "ğŸ“‰" if direction == "ä¸‹é™" else "â¡ï¸"
            report += f"- {keyword}: {volume}æ¬¡æœç´¢ {trend_icon}\n"
        
        report += "\n## å»ºè®®æ–¹å‘\n"
        report += "1. å…³æ³¨AIè‡ªåŠ¨åŒ–å’Œåœ¨çº¿æ•™è‚²é¢†åŸŸï¼ˆè¶‹åŠ¿ä¸Šå‡ï¼‰\n"
        report += "2. ç¼–ç¨‹å’Œç”µå•†ç±»æœºä¼šå—æ¬¢è¿åº¦è¾ƒé«˜\n"
        report += "3. è¢«åŠ¨æ”¶å…¥ç›¸å…³æœç´¢é‡æŒç»­å¢é•¿\n"
        
        return report
    
    def run_collection(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®æ”¶é›†æµç¨‹"""
        logger.info("å¼€å§‹å¸‚åœºæ•°æ®æ”¶é›†...")
        
        # æ”¶é›†æœºä¼šæ•°æ®
        opportunities = self.collect_online_opportunities()
        
        # åˆ†æè¶‹åŠ¿
        trends = self.analyze_trends()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        
        # ä¿å­˜æŠ¥å‘Š
        with open("market_analysis_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        logger.info(f"æ•°æ®æ”¶é›†å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜")
        return report

if __name__ == "__main__":
    collector = MarketDataCollector()
    report = collector.run_collection()
    print(report)