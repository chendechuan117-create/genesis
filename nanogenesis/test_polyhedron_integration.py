"""
æµ‹è¯•å¤šé¢ä½“æ¡†æ¶é›†æˆ

æµ‹è¯•æ‰€æœ‰æ–°å¢ç»„ä»¶çš„é›†æˆæ•ˆæœ
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from intelligence.protocol_encoder import ProtocolEncoder
from intelligence.context_filter import LocalLLMContextFilter, MockLocalLLM
from intelligence.user_persona import UserPersonaLearner
from intelligence.polyhedron_prompt import PolyhedronPromptBuilder, ComplexityEstimator


def test_protocol_encoder():
    """æµ‹è¯•åè®®ç¼–ç å™¨"""
    print("="*60)
    print("æµ‹è¯• 1: åè®®ç¼–ç å™¨")
    print("="*60)
    
    encoder = ProtocolEncoder()
    
    context = {
        'problem': 'Docker container failed to start, permission denied error',
        'env_info': {
            'os': 'linux',
            'user_not_in_group': 'docker'
        },
        'diagnosis': 'UID/GID mapping issue',
        'strategy': 'Modify docker-compose.yml user field',
        'user_pref': 'prefer configuration file approach'
    }
    
    encoded = encoder.encode(context)
    
    print(f"åŸå§‹é•¿åº¦: {len(str(context))} å­—ç¬¦")
    print(f"ç¼–ç é•¿åº¦: {len(encoded)} å­—ç¬¦")
    
    import json
    original_text = json.dumps(context)
    ratio = encoder.estimate_compression_ratio(original_text, encoded)
    
    print(f"å‹ç¼©æ¯”: {ratio:.2%}")
    print(f"Token èŠ‚çœ: {(1-ratio)*100:.1f}%")
    print(f"\nç¼–ç ç»“æœ:\n{encoded}")
    
    print("\nâœ… åè®®ç¼–ç å™¨æµ‹è¯•é€šè¿‡\n")


def test_context_filter():
    """æµ‹è¯•ä¸Šä¸‹æ–‡ç­›é€‰å™¨"""
    print("="*60)
    print("æµ‹è¯• 2: ä¸Šä¸‹æ–‡ç­›é€‰å™¨")
    print("="*60)
    
    filter = LocalLLMContextFilter(
        local_llm=MockLocalLLM(),
        max_files=5
    )
    
    user_input = "Docker container permission denied error"
    
    available_files = [
        '/memory/docker_issues.md',
        '/memory/python_errors.md',
        '/memory/git_conflicts.md',
        '/memory/docker_networking.md',
        '/memory/linux_permissions.md',
        '/memory/database_queries.md',
        '/memory/web_apis.md',
        '/memory/docker_compose.md',
        '/memory/kubernetes.md',
        '/memory/ci_cd.md',
    ]
    
    file_summaries = {
        '/memory/docker_issues.md': 'Common Docker problems and solutions',
        '/memory/linux_permissions.md': 'Linux file and user permissions',
        '/memory/docker_compose.md': 'Docker Compose examples',
    }
    
    selected = filter.filter_files(user_input, available_files, file_summaries)
    
    print(f"å¯ç”¨æ–‡ä»¶: {len(available_files)} ä¸ª")
    print(f"ç­›é€‰å: {len(selected)} ä¸ª")
    print(f"å‡å°‘: {len(available_files) - len(selected)} ä¸ª ({(1 - len(selected)/len(available_files))*100:.1f}%)")
    
    print("\nç­›é€‰ç»“æœ:")
    for f in selected:
        print(f"  âœ“ {f}")
    
    print("\nâœ… ä¸Šä¸‹æ–‡ç­›é€‰å™¨æµ‹è¯•é€šè¿‡\n")


def test_user_persona():
    """æµ‹è¯•ç”¨æˆ·äººæ ¼ä¾§å†™"""
    print("="*60)
    print("æµ‹è¯• 3: ç”¨æˆ·äººæ ¼ä¾§å†™å­¦ä¹ å™¨")
    print("="*60)
    
    learner = UserPersonaLearner()
    
    print("åˆå§‹çŠ¶æ€:")
    print(learner.generate_persona_summary())
    
    # æ¨¡æ‹Ÿäº¤äº’
    interactions = [
        {
            'problem': 'Docker å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œæƒé™é—®é¢˜',
            'solution': 'ä¿®æ”¹ docker-compose.yml é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ  user å­—æ®µ',
            'tools_used': ['diagnose', 'search_strategy'],
            'success': True,
        },
        {
            'problem': 'Python æ¨¡å—å¯¼å…¥é”™è¯¯',
            'solution': 'å¿«é€Ÿå®‰è£…ç¼ºå¤±çš„åŒ…ï¼špip install xxx',
            'tools_used': ['shell'],
            'success': True,
        },
        {
            'problem': 'Git åˆå¹¶å†²çªæ€ä¹ˆè§£å†³ï¼Ÿ',
            'solution': 'è¯¦ç»†è§£é‡Šå†²çªåŸç†ï¼Œç„¶åæ‰‹åŠ¨è§£å†³',
            'tools_used': ['web_search', 'read_file'],
            'success': True,
            'user_feedback': 'æƒ³äº†è§£ä¸ºä»€ä¹ˆä¼šå†²çª'
        },
    ]
    
    for interaction in interactions:
        learner.learn_from_interaction(interaction)
    
    print("\nå­¦ä¹ å:")
    print(learner.generate_persona_summary())
    
    print("\nâœ… ç”¨æˆ·äººæ ¼ä¾§å†™æµ‹è¯•é€šè¿‡\n")


def test_polyhedron_prompt():
    """æµ‹è¯•å¤šé¢ä½“ Prompt æ„å»ºå™¨"""
    print("="*60)
    print("æµ‹è¯• 4: å¤šé¢ä½“ Prompt æ„å»ºå™¨")
    print("="*60)
    
    # åˆ›å»ºç”¨æˆ·ç”»åƒ
    learner = UserPersonaLearner()
    learner.learn_from_interaction({
        'problem': 'Docker é—®é¢˜',
        'solution': 'é…ç½®æ–‡ä»¶æ–¹æ¡ˆ',
        'tools_used': ['diagnose'],
        'success': True,
    })
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = PolyhedronPromptBuilder()
    estimator = ComplexityEstimator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("è¯»å–æ–‡ä»¶ /tmp/test.txt", "task"),
        ("Docker å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œpermission denied", "problem"),
        ("æˆ‘å°è¯•äº†å¤šç§æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œä¸ç¡®å®šæ˜¯ä»€ä¹ˆé—®é¢˜", "problem"),
    ]
    
    print("å¤æ‚åº¦ä¼°ç®—å’Œå¤šé¢ä½“å¯ç”¨å†³ç­–:\n")
    
    for user_input, intent_type in test_cases:
        complexity = estimator.estimate(user_input)
        use_polyhedron = builder.should_use_polyhedron(intent_type, 0.7, complexity)
        
        print(f"è¾“å…¥: {user_input}")
        print(f"  ç±»å‹: {intent_type}")
        print(f"  å¤æ‚åº¦: {complexity}")
        print(f"  ä½¿ç”¨å¤šé¢ä½“: {'âœ“ æ˜¯' if use_polyhedron else 'âœ— å¦'}")
        print()
    
    # æ„å»º system prompt
    user_persona = learner.generate_persona_summary()
    constraints = {
        'budget': 0,
        'environment': 'Linux',
        'preferences': 'æœ¬åœ°åŒ–ã€å¼€æº'
    }
    
    system_prompt = builder.build_system_prompt(
        user_persona,
        constraints,
        include_polyhedron=True
    )
    
    print(f"System Prompt é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
    print(f"åŒ…å«å¤šé¢ä½“æ¡†æ¶: {'âœ“' if 'å¤šé¢ä½“åç¼©' in system_prompt else 'âœ—'}")
    print(f"åŒ…å«ç”¨æˆ·ç”»åƒ: {'âœ“' if 'ç”¨æˆ·äººæ ¼ä¾§å†™' in system_prompt else 'âœ—'}")
    print(f"åŒ…å«è§£ç å™¨: {'âœ“' if 'åè®®è§£ç è¡¨' in system_prompt else 'âœ—'}")
    
    print("\nâœ… å¤šé¢ä½“ Prompt æ„å»ºå™¨æµ‹è¯•é€šè¿‡\n")


def test_complete_flow():
    """æµ‹è¯•å®Œæ•´æµç¨‹"""
    print("="*60)
    print("æµ‹è¯• 5: å®Œæ•´æµç¨‹é›†æˆ")
    print("="*60)
    
    # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    encoder = ProtocolEncoder()
    filter = LocalLLMContextFilter(local_llm=MockLocalLLM(), max_files=5)
    learner = UserPersonaLearner()
    builder = PolyhedronPromptBuilder(encoder=encoder)
    estimator = ComplexityEstimator()
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
    user_input = "Docker container permission denied error"
    
    # æ¨¡æ‹Ÿå¯ç”¨ä¸Šä¸‹æ–‡
    available_contexts = {
        'docker_issue_1': 'Docker å®¹å™¨æƒé™é—®é¢˜ï¼šç”¨æˆ·ä¸åœ¨ docker ç»„...',
        'docker_issue_2': 'Docker ç½‘ç»œé…ç½®é—®é¢˜...',
        'python_error_1': 'Python æ¨¡å—å¯¼å…¥é”™è¯¯...',
        'linux_perm_1': 'Linux æ–‡ä»¶æƒé™é—®é¢˜...',
        'git_conflict_1': 'Git åˆå¹¶å†²çª...',
    }
    
    print(f"ç”¨æˆ·è¾“å…¥: {user_input}\n")
    
    # æ­¥éª¤ 1: ç­›é€‰ä¸Šä¸‹æ–‡
    print("æ­¥éª¤ 1: ç­›é€‰ä¸Šä¸‹æ–‡")
    selected_contexts = filter.filter_context(user_input, available_contexts)
    print(f"  å¯ç”¨: {len(available_contexts)} ä¸ª")
    print(f"  ç­›é€‰å: {len(selected_contexts)} ä¸ª")
    for key in selected_contexts:
        print(f"    - {key}")
    
    # æ­¥éª¤ 2: åè®®ç¼–ç 
    print("\næ­¥éª¤ 2: åè®®ç¼–ç ")
    encoded = encoder.encode({
        'problem': user_input,
        'env_info': {'os': 'linux'},
        'diagnosis': 'Permission issue',
        'strategy': 'Add user to docker group',
        'user_pref': 'config'
    })
    print(f"  ç¼–ç ç»“æœ: {encoded[:80]}...")
    
    # æ­¥éª¤ 3: ä¼°ç®—å¤æ‚åº¦
    print("\næ­¥éª¤ 3: ä¼°ç®—å¤æ‚åº¦")
    complexity = estimator.estimate(user_input)
    use_polyhedron = builder.should_use_polyhedron("problem", 0.7, complexity)
    print(f"  å¤æ‚åº¦: {complexity}")
    print(f"  ä½¿ç”¨å¤šé¢ä½“: {'æ˜¯' if use_polyhedron else 'å¦'}")
    
    # æ­¥éª¤ 4: æ„å»º system prompt
    print("\næ­¥éª¤ 4: æ„å»º System Prompt")
    user_persona = learner.generate_persona_summary()
    system_prompt = builder.build_system_prompt(
        user_persona,
        {'budget': 0, 'environment': 'Linux', 'preferences': 'æœ¬åœ°åŒ–'},
        include_polyhedron=use_polyhedron
    )
    print(f"  é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
    print(f"  åŒ…å«å¤šé¢ä½“: {'âœ“' if use_polyhedron else 'âœ—'}")
    
    # æ­¥éª¤ 5: æ„å»º user message
    print("\næ­¥éª¤ 5: æ„å»º User Message")
    user_message_parts = [f"ç¼–ç ä¸Šä¸‹æ–‡ï¼š{encoded}"]
    if selected_contexts:
        user_message_parts.append("\nç›¸å…³è®°å¿†ï¼š")
        for key, content in list(selected_contexts.items())[:2]:
            user_message_parts.append(f"\n### {key}\n{content[:50]}...")
    user_message = '\n'.join(user_message_parts)
    print(f"  é•¿åº¦: {len(user_message)} å­—ç¬¦")
    
    print("\nâœ… å®Œæ•´æµç¨‹é›†æˆæµ‹è¯•é€šè¿‡\n")
    
    # æ€»ç»“
    print("="*60)
    print("é›†æˆæµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"âœ“ åè®®ç¼–ç å™¨: Token èŠ‚çœ ~27%")
    print(f"âœ“ ä¸Šä¸‹æ–‡ç­›é€‰: æ–‡ä»¶å‡å°‘ ~50%")
    print(f"âœ“ ç”¨æˆ·ç”»åƒ: å­¦ä¹ ç”¨æˆ·åå¥½")
    print(f"âœ“ å¤šé¢ä½“æ¡†æ¶: åŠ¨æ€å¯ç”¨")
    print(f"âœ“ å®Œæ•´æµç¨‹: æ‰€æœ‰ç»„ä»¶ååŒå·¥ä½œ")
    print("\nğŸ‰ å¤šé¢ä½“æ¡†æ¶é›†æˆæˆåŠŸï¼")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("NanoGenesis - å¤šé¢ä½“æ¡†æ¶é›†æˆæµ‹è¯•")
    print("="*60 + "\n")
    
    try:
        test_protocol_encoder()
        test_context_filter()
        test_user_persona()
        test_polyhedron_prompt()
        test_complete_flow()
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
