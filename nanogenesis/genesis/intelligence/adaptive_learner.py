"""
AdaptiveLearner v2 â€” LLM é©±åŠ¨çš„è‡ªåæ€å­¦ä¹ å™¨
=============================================
æ ¸å¿ƒè½¬å˜ï¼š
  v1: ç¡¬ç¼–ç å…³é”®è¯ + å›ºå®š delta â†’ ç»™é£æ ¼å‚æ•°æ‰“åˆ†
  v2: å­˜å‚¨åŸå§‹äº¤äº’ â†’ æ¯ N æ¬¡è§¦å‘ LLM è‡ªåæ€ â†’ ç”Ÿæˆ cognitive_insights

æ²¡æœ‰ç¡¬ç¼–ç çš„å…³é”®è¯ã€é˜ˆå€¼æˆ–è°ƒæ•´å¹…åº¦ã€‚
æ‰€æœ‰è§„å¾‹ç”± LLM è‡ªèº«ä»äº¤äº’å†å²ä¸­å½’çº³ï¼Œå†™å…¥ cognitive_insightsã€‚
cognitive_insights ç›´æ¥æ³¨å…¥ system_promptï¼Œå½¢æˆè¡Œä¸ºæŒ‡å¯¼ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
  learner = AdaptiveLearner(storage_path="...", reflection_interval=5)
  
  # è®°å½•ä¸€æ¬¡äº¤äº’ï¼ˆåŒæ­¥ï¼Œè½»é‡ï¼‰
  learner.observe_interaction(user_message, assistant_response, user_reaction)
  
  # æ¯ N æ¬¡äº¤äº’åï¼Œå¤–éƒ¨è°ƒç”¨è§¦å‘å¼‚æ­¥åæ€ï¼ˆéœ€ä¼ å…¥ LLM chat å‡½æ•°ï¼‰
  await learner.trigger_reflection(llm_chat_fn=cognition.chat)
  
  # ç”Ÿæˆæ³¨å…¥ system_prompt çš„ insight æ®µè½
  prompt_addon = learner.generate_adaptive_prompt()
"""

import json
import asyncio
import logging
from typing import Dict, List, Optional, Any, Callable, Awaitable
from dataclasses import dataclass, field
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class AdaptiveState:
    """
    ç²¾ç®€åçš„è‡ªé€‚åº”çŠ¶æ€ã€‚
    ä¸å†ç»´æŠ¤æ‰“åˆ†å‚æ•°ï¼Œåªä¿ç•™ï¼š
      - åŸå§‹äº¤äº’è®¡æ•°
      - LLM è‡ªåæ€ç”Ÿæˆçš„ cognitive_insights
    """
    total_interactions: int = 0
    last_reflection_at: int = 0         # ä¸Šæ¬¡åæ€æ—¶çš„ interaction æ•°é‡
    cognitive_insights: List[str] = field(default_factory=list)

    # å‘åå…¼å®¹ï¼šä¿ç•™æ—§å­—æ®µï¼ˆä¸å†ä½¿ç”¨ï¼Œä½†é¿å…åŠ è½½æ—§ JSON æŠ¥é”™ï¼‰
    prefers_concise: float = 0.5
    prefers_technical: float = 0.5
    prefers_proactive: float = 0.5
    uses_emoji: float = 0.0
    message_length_avg: float = 50.0
    formality: float = 0.5
    positive_signals: int = 0
    negative_signals: int = 0
    confidence: float = 0.0


class AdaptiveLearner:
    """
    LLM é©±åŠ¨çš„è‡ªé€‚åº”å­¦ä¹ å™¨ã€‚

    å‚æ•°ï¼š
      storage_path        : JSON çŠ¶æ€æ–‡ä»¶è·¯å¾„
      reflection_interval : æ¯éš”å¤šå°‘æ¬¡äº¤äº’è§¦å‘ä¸€æ¬¡ LLM åæ€
      max_insights        : cognitive_insights æœ€å¤§æ¡æ•°ï¼ˆFIFO æ·˜æ±°ï¼‰
      history_window      : æ¯æ¬¡åæ€å‚è€ƒæœ€è¿‘ N æ¡åŸå§‹äº¤äº’
    """

    def __init__(
        self,
        storage_path: str = "./data/adaptive_learning.json",
        reflection_interval: int = 5,
        max_insights: int = 12,
        history_window: int = 10,
    ):
        self.storage_path = Path(storage_path)
        self.storage_path.parent.mkdir(parents=True, exist_ok=True)
        self.reflection_interval = reflection_interval
        self.max_insights = max_insights
        self.history_window = history_window

        self.state = self._load()
        self.interaction_history: List[Dict[str, Any]] = []

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def observe_interaction(
        self,
        user_message: str,
        assistant_response: str,
        user_reaction: Optional[str] = None,
    ) -> None:
        """
        è®°å½•ä¸€æ¬¡äº¤äº’ï¼ˆåŒæ­¥ï¼Œè½»é‡ï¼Œæ—  LLM è°ƒç”¨ï¼‰ã€‚
        ä»…å­˜å‚¨åŸå§‹æ•°æ®ï¼Œä¸åšä»»ä½•ç¡¬ç¼–ç åˆ†æã€‚
        """
        self.interaction_history.append({
            "timestamp": datetime.now().isoformat(),
            "user": user_message[:500],           # æˆªæ–­é˜²æ­¢è¿‡é•¿
            "assistant": assistant_response[:500],
            "reaction": (user_reaction or "")[:200],
        })
        self.state.total_interactions += 1
        self._save()

    def should_reflect(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åˆ°äº†è§¦å‘ LLM åæ€çš„æ—¶æœº"""
        due = self.state.total_interactions - self.state.last_reflection_at
        return due >= self.reflection_interval and len(self.interaction_history) >= 2

    async def trigger_reflection(
        self,
        llm_chat_fn: Callable[[List[Dict]], Awaitable[Any]],
    ) -> None:
        """
        è§¦å‘ LLM è‡ªåæ€ï¼š
          1. å–æœ€è¿‘ N æ¡äº¤äº’å†å²
          2. æ„å»ºåæ€ prompt
          3. è§£æ LLM è¾“å‡ºä¸º insight åˆ—è¡¨
          4. è¿½åŠ åˆ° cognitive_insights (FIFO)

        Args:
            llm_chat_fn: æ¥å— messages listã€è¿”å›æœ‰ .content å±æ€§çš„å¯¹è±¡çš„å¼‚æ­¥å‡½æ•°
                         ï¼ˆä¸ cognition.chat æ¥å£å…¼å®¹ï¼‰
        """
        if not self.should_reflect():
            return

        recent = self.interaction_history[-self.history_window:]
        history_text = self._format_history(recent)

        prompt = (
            f"ä½ åˆšåˆšå®Œæˆäº† {len(recent)} æ¬¡å¯¹è¯äº¤äº’ï¼Œä»¥ä¸‹æ˜¯è®°å½•ï¼š\n\n"
            f"{history_text}\n\n"
            "è¯·ä»ä¸­å½’çº³ 3~5 æ¡ç®€æ´çš„è§„å¾‹ï¼Œæ¶µç›–ï¼š\n"
            "1. è¿™ä¸ªç”¨æˆ·çš„æ²Ÿé€šåå¥½ï¼ˆè¯­æ°”ã€è¯¦ç»†ç¨‹åº¦ã€æŠ€æœ¯æ·±åº¦ç­‰ï¼‰\n"
            "2. å“ªäº›æ‰§è¡Œæ–¹å¼/å·¥å…·/ç­–ç•¥æœ‰æ•ˆï¼Œå“ªäº›éœ€è¦é¿å…\n"
            "3. ä»»ä½•å…¶ä»–å€¼å¾—è®°ä½çš„è¡Œä¸ºæ¨¡å¼\n\n"
            "æ ¼å¼ï¼šæ¯æ¡è§„å¾‹ä¸€è¡Œï¼Œä»¥ - å¼€å¤´ï¼Œç”¨ä¸­æ–‡ï¼Œç®€çŸ­ç²¾ç‚¼ï¼ˆä¸è¶…è¿‡ 25 å­—/æ¡ï¼‰ã€‚\n"
            "ç›´æ¥è¾“å‡ºè§„å¾‹åˆ—è¡¨ï¼Œä¸è¦æœ‰å‰è¨€æˆ–è§£é‡Šã€‚"
        )

        try:
            resp = await llm_chat_fn([{"role": "user", "content": prompt}])
            raw = resp.content.strip() if resp else ""
            insights = self._parse_insights(raw)

            for insight in insights:
                self.add_cognitive_insight(insight)

            self.state.last_reflection_at = self.state.total_interactions
            self._save()
            logger.info(f"ğŸ§  AdaptiveLearner åæ€å®Œæˆï¼Œæ–°å¢ {len(insights)} æ¡ insight (å…± {len(self.state.cognitive_insights)} æ¡)")

        except Exception as e:
            logger.warning(f"AdaptiveLearner åæ€å¤±è´¥ï¼ˆè·³è¿‡ï¼‰: {e}")

    async def trigger_anchor_reflection(
        self,
        llm_chat_fn: Callable[[List[Dict]], Awaitable[Any]],
        decisions: List[Dict],
    ) -> None:
        """
        æ·±åº¦é”šç‚¹åæ€ â€” ä»…åœ¨é”šç‚¹äº‹ä»¶ï¼ˆå›æº¯ã€å¤±è´¥ï¼‰è§¦å‘ã€‚
        
        ä¸ trigger_reflection() ä¸åŒï¼š
          - trigger_reflection : ä»å¯¹è¯å†å²æç‚¼ç”¨æˆ·åå¥½ï¼ˆåŠ æ³•ï¼‰
          - trigger_anchor_reflection : ä»å†³ç­–æ—¥å¿—æç‚¼åŸŸæ— å…³çš„è®¤çŸ¥åŸç†ï¼ˆä¹˜æ³•ï¼‰
        
        ç›®æ ‡ä¸æ˜¯"A ç±»é—®é¢˜ç”¨ A æ–¹æ³•"ï¼Œè€Œæ˜¯"ä»€ä¹ˆè®¤çŸ¥å§¿æ€å¯¼è‡´äº†æ›´å¥½/æ›´å·®çš„é”šç‚¹é€‰æ‹©"ã€‚

        Args:
            llm_chat_fn: å¼‚æ­¥ LLM chat å‡½æ•°
            decisions  : get_recent_decisions() è¿”å›çš„å†³ç­–è®°å½•åˆ—è¡¨
        """
        if not decisions:
            return

        # æ„å»ºå†³ç­–è®°å½•æ‘˜è¦ï¼Œçªå‡ºæˆåŠŸ vs å¤±è´¥çš„å¯¹æ¯”
        lines = []
        for d in decisions[:12]:
            outcome_emoji = "âœ…" if d["outcome"] == "success" else "âŒ"
            opts = ", ".join(d["anchor_options"][:4]) if d["anchor_options"] else "æœªè®°å½•"
            lines.append(
                f"{outcome_emoji} [{d['problem_type']}] å€™é€‰é”šç‚¹: [{opts}] â†’ é€‰æ‹©: {d['chosen_anchor'][:80]}"
            )
        decisions_text = "\n".join(lines)

        prompt = (
            "ä»¥ä¸‹æ˜¯æˆ‘æœ€è¿‘çš„å†³ç­–è®°å½•ï¼Œè®°å½•äº†æ¯æ¬¡ä»»åŠ¡å¼€å§‹æ—¶æœ‰å“ªäº›å¯èƒ½çš„é”šç‚¹ï¼ˆå·¥å…·/æ–¹æ³•ï¼‰ï¼Œ"
            "æˆ‘å®é™…é€‰æ‹©äº†å“ªä¸ªï¼Œä»¥åŠç»“æœæ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼š\n\n"
            f"{decisions_text}\n\n"
            "è¯·åŸºäºè¿™äº›å†³ç­–çš„æ¨¡å¼ï¼Œå½’çº³ 2~4 æ¡å…³äº**å¦‚ä½•é€‰æ‹©æ›´å¥½èµ·ç‚¹**çš„é€šç”¨è®¤çŸ¥åŸç†ã€‚\n\n"
            "å…³é”®è¦æ±‚ï¼š\n"
            "- åŸç†å¿…é¡»ä¸å…·ä½“ä»»åŠ¡ç±»å‹æ— å…³ï¼ˆä¸æ˜¯'éŸ³é¢‘é—®é¢˜ç”¨ PulseAudio'è¿™ç§ç±»å‹ï¼‰\n"
            "- åŸç†åº”è¯¥æ˜¯å…³äº'å¦‚ä½•å®šå‘æ€è€ƒ'æˆ–'ä»€ä¹ˆä¿¡å·æ„å‘³ç€åº”è¯¥æ¢èµ·ç‚¹'çš„è®¤çŸ¥è§„å¾‹\n"
            "- ä¾‹å¦‚ï¼š'å¤±è´¥çš„é”šç‚¹é€šå¸¸æ˜¯ä»é›¶æ„å»ºï¼Œè€Œéå¯»æ‰¾å·²æœ‰è§£'\n\n"
            "ç›´æ¥è¾“å‡ºåŸç†åˆ—è¡¨ï¼Œæ¯æ¡ä»¥ - å¼€å¤´ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡ 30 å­—/æ¡ã€‚"
        )

        try:
            resp = await llm_chat_fn([{"role": "user", "content": prompt}])
            raw = resp.content.strip() if resp else ""
            insights = self._parse_insights(raw)

            for insight in insights:
                self.add_cognitive_insight(f"[é”šç‚¹è®¤çŸ¥] {insight}")

            self._save()
            logger.info(
                f"ğŸ” é”šç‚¹æ·±åº¦åæ€å®Œæˆï¼Œæ–°å¢ {len(insights)} æ¡è®¤çŸ¥åŸç† "
                f"(å…± {len(self.state.cognitive_insights)} æ¡)"
            )

        except Exception as e:
            logger.warning(f"é”šç‚¹åæ€å¤±è´¥ï¼ˆè·³è¿‡ï¼‰: {e}")

    def add_cognitive_insight(self, insight: str) -> None:
        """æ‰‹åŠ¨æ·»åŠ ä¸€æ¡ insightï¼ˆä¹Ÿå¯ä»å¤–éƒ¨è°ƒç”¨ï¼Œä¾‹å¦‚ backtrack è§¦å‘æ—¶ï¼‰"""

        insight = insight.strip()
        if not insight or insight in self.state.cognitive_insights:
            return
        self.state.cognitive_insights.append(insight)
        if len(self.state.cognitive_insights) > self.max_insights:
            self.state.cognitive_insights.pop(0)  # FIFO æ·˜æ±°æœ€æ—§çš„
        self._save()

    def generate_adaptive_prompt(self) -> str:
        """
        ç”Ÿæˆæ³¨å…¥ system_prompt çš„è‡ªé€‚åº”æ®µè½ã€‚
        åªæç‚¼ cognitive_insightsï¼Œä¸å†æœ‰ä»»ä½•è¯„åˆ†æˆ–ç¡¬ç¼–ç è¡¨è¾¾ã€‚
        å¦‚æœæ²¡æœ‰ insightï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆä¸å½±å“ç°æœ‰ promptï¼‰ã€‚
        """
        insights = self.state.cognitive_insights
        if not insights:
            return ""

        lines = ["", "ã€ğŸ“– ä»å†å²äº¤äº’å½’çº³çš„è¡Œä¸ºè§„å¾‹ï¼ˆè‡ªåŠ¨å­¦ä¹ ï¼‰ã€‘"]
        for insight in insights[-8:]:   # åªç”¨æœ€è¿‘ 8 æ¡ï¼Œé¿å…è¿‡é•¿
            lines.append(f"- {insight}")
        lines.append("")
        return "\n".join(lines)

    def get_stats(self) -> Dict[str, Any]:
        """è¿”å›å½“å‰å­¦ä¹ çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
        return {
            "total_interactions": self.state.total_interactions,
            "last_reflection_at": self.state.last_reflection_at,
            "insight_count": len(self.state.cognitive_insights),
            "insights": self.state.cognitive_insights,
            "next_reflection_in": max(
                0, self.reflection_interval - (
                    self.state.total_interactions - self.state.last_reflection_at
                )
            ),
        }

    # ------------------------------------------------------------------
    # Internals
    # ------------------------------------------------------------------

    def _format_history(self, interactions: List[Dict]) -> str:
        lines = []
        for i, item in enumerate(interactions, 1):
            lines.append(f"[{i}] ç”¨æˆ·: {item.get('user', '')}")
            lines.append(f"    Genesis: {item.get('assistant', '')}")
            if item.get("reaction"):
                lines.append(f"    ç”¨æˆ·ååº”: {item['reaction']}")
        return "\n".join(lines)

    def _parse_insights(self, raw: str) -> List[str]:
        """ä» LLM è¾“å‡ºä¸­æå–ä»¥ - å¼€å¤´çš„ insight è¡Œ"""
        insights = []
        for line in raw.splitlines():
            line = line.strip()
            if line.startswith("-"):
                clean = line.lstrip("-").strip()
                if clean and len(clean) > 3:
                    insights.append(clean)
        return insights[:6]  # æœ€å¤šå– 6 æ¡é˜²æ­¢è¿‡è½½

    def _save(self) -> None:
        from dataclasses import asdict
        data = {
            "state": asdict(self.state),
            "last_updated": datetime.now().isoformat(),
        }
        try:
            with open(self.storage_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.warning(f"AdaptiveLearner ä¿å­˜å¤±è´¥: {e}")

    def _load(self) -> AdaptiveState:
        if not self.storage_path.exists():
            return AdaptiveState()
        try:
            with open(self.storage_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            # å…¼å®¹æ—§æ ¼å¼ï¼ˆv1 å­˜çš„æ˜¯ pattern å­—æ®µï¼‰
            raw = data.get("state") or data.get("pattern") or {}
            # è¿‡æ»¤æ‰ AdaptiveState ä¸è®¤è¯†çš„å­—æ®µï¼Œé˜²æ­¢ __init__ æŠ¥é”™
            valid_fields = AdaptiveState.__dataclass_fields__.keys()
            filtered = {k: v for k, v in raw.items() if k in valid_fields}
            return AdaptiveState(**filtered)
        except Exception as e:
            logger.warning(f"AdaptiveLearner åŠ è½½å¤±è´¥ï¼Œé‡ç½®: {e}")
            return AdaptiveState()
